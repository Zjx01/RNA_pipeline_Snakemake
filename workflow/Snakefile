import glob
import os
from snakemake.utils import min_version
import yaml 

##### set minimum snakemake version #####
min_version("8.8.0")



#### setup report ####
#### configfile:"config/config.yaml"####

with open('config/config.yaml', 'r') as config_file:
    config = yaml.safe_load(config_file)


with open(config['sample_file']) as fh:
    sample_reads = dict()
    for line in fh:
        fields = line.strip().split('\t')
        files = [
            path
            for f in fields[1:]
            for path in glob.glob(f)
        ]
        if len(files) != 2:
           raise ValueError(f"Expected two read files per samples, {fields[0]} has {len(files)}: {files}")
        sample_reads[fields[0]] = files
config['sample_reads'] = sample_reads

def get_input_fastqs(wildcards):
    return config['sample_reads'][wildcards.sample]


def get_input_fastq_r1(wildcards):
    """Selects the R1 FASTQ file dynamically based on filename pattern."""
    files = config['sample_reads'][wildcards.sample]
    r1_file = next((f for f in files if f.endswith("_R1.fastq.gz")), None)

    if not r1_file:
        raise ValueError(f"Missing R1 file for sample {wildcards.sample} in config.yaml")

    return r1_file

def get_input_fastq_r2(wildcards):
    """Selects the R2 FASTQ file dynamically based on filename pattern."""
    files = config['sample_reads'][wildcards.sample]
    r2_file = next((f for f in files if f.endswith("_R2.fastq.gz")), None)

    if not r2_file:
        raise ValueError(f"Missing R2 file for sample {wildcards.sample} in config.yaml")

    return r2_file


rule all:
    input:
        ###fastqc###
        expand("results/fastqc/{sample}",sample=config["sample_reads"]),
        ###fastp-QC###
        expand("results/trimmed/{sample}/{sample}_R1.fastq.gz", sample=config["sample_reads"]),
        expand("results/trimmed/{sample}/{sample}_R2.fastq.gz", sample=config["sample_reads"]),
        expand("results/trimmed/{sample}/{sample}_merged.fastq", sample=config["sample_reads"]),
        # ###bowtie2-reference genome/human genome filter"#### 
        # #"resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz",
        expand("results/metagenome/{sample}/{sample}.fastq",sample=config["sample_reads"]),
        expand("results/metagenome/{sample}/{sample}.fasta",sample=config["sample_reads"]),
        # # ###contig###
        expand("results/contigs/{sample}/final.contigs.fa",sample=config["sample_reads"]),
        "results/contigs/all_contigs.fasta",
        "results/filtered_contigs/length{LEN}up.all_contigs.fa".format(LEN=config["contig_filter_length"]),
        "results/filtered_contigs/length{LEN}up.all_contigs.sorted.fa".format(LEN=config["contig_filter_length"]),
        # ###minimap2###
        "results/minimap2/length{LEN}up.all_contigs.sorted.mmi".format(LEN=config["contig_filter_length"]),
        expand("results/minimap2/contig_bam/{sample}.bam",sample=config["sample_reads"]),
        "results/minimap2/length{G_LEN}up.contig.genes.mmi".format(G_LEN=config["contig_gene_length"]),
        expand("results/minimap2/gene_bam/{sample}.bam",sample=config["sample_reads"]),
        ###bam_check###
        #"results/minimap2/corrupted_bam_genes",
        #"results/minimap2/corrupted_bam_contigs",
        # ###vamb###
        "results/vamb/contigs",
        "results/vamb/genes",
        # ###vamb_rpkm_tabulation###
        "results/rpkm/contigs_rpkm.csv",
        "results/rpkm/genes_rpkm.csv",
        "results/rpkm/contigs/contigs_lengths.csv",
        "results/rpkm/genes/gene_lengths.csv",
        # # "results/rpkm/reads/sample_total_reads.csv",
        # # "results/rpkm/contigs/contig_reads_table.csv",
        # ###vamb_reads###
        # expand("results/rpkm/reads/total_reads/{sample}.total_reads", sample=config["sample_reads"]),
        # expand("results/rpkm/reads/reads/{sample}.reads", sample=config["sample_reads"]),
        # ###prodigal###
        "results/prodigal/length{LEN}up/contig.genes.fna".format(LEN=config["contig_filter_length"]),
        "results/prodigal/length{LEN}up/length{LEN}up.all_contigs.faa".format(LEN=config["contig_filter_length"]),
        "results/prodigal/length{LEN}up/length{LEN}up.all_contigs.out".format(LEN=config["contig_filter_length"]),
        "results/prodigal/length{LEN}up/length{G_LEN}up.contig.genes.fna".format(G_LEN=config["contig_gene_length"],LEN=config["contig_filter_length"]),
        # ###checkM###
        # "results/checkM/checkm_data_db",
        # "results/checkM/SGB",
	    # ###viral###
        # #"results/viral/vsorter/db",
        # #"results/viral/vsorter/vsorter2",
        # "results/viral/vibrant",
        # "results/viral/vibrant_db_done.txt"


	
rule fastqc:
    input: get_input_fastqs
    output: directory("results/fastqc/{sample}/") 
    log:"logs/fastqc/{sample}.log"
    threads:1
    resources:
        mem_mb = 20000
    conda: "envs/fastqc.yaml"
    shell:
        "mkdir -p results/fastqc/{wildcards.sample} && fastqc -o {output} -t {threads} {input}"



rule trim:
    input: 
        r1=get_input_fastq_r1, 
        r2=get_input_fastq_r2
    output:
        r1="results/trimmed/{sample}/{sample}_R1.fastq.gz",
        r2="results/trimmed/{sample}/{sample}_R2.fastq.gz",
        merged="results/trimmed/{sample}/{sample}_merged.fastq"
    log:
        "logs/fastp-trim/{sample}.log"
    threads: 1
    conda:
        "envs/fastp.yaml"
    shell:
        """
        fastp \
            --in1 {input.r1} \
            --in2 {input.r2} \
            --out1 {output.r1} \
            --out2 {output.r2} \
            -q 20 -m --merged_out {output.merged} \
            > {log} 2>&1
        """



rule human_filter_reference:
    params: 
        url=config["ref_ftp"]
    output:
        "resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
    conda:
        "envs/wget.yaml"	
    shell:
        "wget --no-check-certificate -O {output} {params.url}"


#rule human_filter_bowtie2_index:
#    input: rules.human_filter_reference.output
#    output:
#        multiext(
#            "resources/Homo_sapiens.GRCh38.dna.primary_assembly",
#            ".1.bt2",
#            ".2.bt2",
#            ".3.bt2",
#            ".4.bt2",
#            ".rev.1.bt2",
#            ".rev.2.bt2"
#       )
#    log: "logs/human_filter/bowtie2/index.log"
#    threads: 30
#    resources: mem_mb=lambda wildcards, input, attempt: max(input.size_mb * 4 * attempt, 40960)
#    conda: "envs/bowtie2.yaml"
#    shell:
#        "bowtie2-build"
#        " --threads {threads}"
#        " {input}"
#        " resources/Homo_sapiens.GRCh38.dna.primary_assembly"
#        " &> {log}"




rule human_genome_filter:
   input:
       #index=rules.human_filter_bowtie2_index.output,
       #merged_fq="results/trimmed/{sample}/{sample}_merged.fastq"
       merged_fq=rules.trim.output.merged
   output:
       metagenome="results/metagenome/{sample}/{sample}.fastq"
   log: "logs/human_filter/bowtie2/humangenome_filter/{sample}.log"
   conda: "envs/bowtie2.yaml"
   threads: 20
   # resources: mem_mb=lambda wildcards, input, attempt: max(input.size_mb * 4 * attempt, 40960)
   shell:
       "bowtie2"
       " --threads {threads}"
       " -x resources/Homo_sapiens.GRCh38.dna.primary_assembly" #{index}
       " -U {input.merged_fq}"
       " --un {output.metagenome}"
       " &> {log}" 


rule fq2fa:
    input: rules.human_genome_filter.output.metagenome
    output:
        metagenome_fa="results/metagenome/{sample}/{sample}.fasta"  
    log:"logs/human_filter/seqtk/fq2fa/{sample}.log"
    conda:"envs/seqtk.yaml"
    threads: 10
    shell:
        "seqtk seq -a {input} > {output} 2> {log}" 



rule get_contig:
    input: rules.fq2fa.output.metagenome_fa
    params: outdir = "results/contigs/{sample}"
    output: 
        "results/contigs/{sample}/final.contigs.fa"
    log:"logs/contigs/megahit/{sample}.log"
    conda:"envs/megahit.yaml"
    threads: 20
    resources: mem_mb=lambda wildcards, input, attempt: max(input.size_mb * 4 * attempt, 20000)
    group: "contig_assembly"
    shell:
        """
        rm -rf {params.outdir}
        megahit -r {input} -o {params.outdir} -t {threads}
        &> {log}
        """


rule unify_all_contigs:
    input: expand("results/contigs/{sample}/final.contigs.fa", sample=config['sample_reads'])
    output: "results/contigs/all_contigs.fasta"
    log: "logs/contigs/all_contig.log"
    group: "contig_assembly"
    threads: 10
    shell:
        """
        for f in {input}; do sample_name=$(basename $(dirname $f)); sed "s/>/>${{sample_name}}C/g" $f >> {output}; done &> {log}
        """


rule contig_filter:
    input:
        "results/contigs/all_contigs.fasta"
    params: 
        LEN=config["contig_filter_length"]  
    output:
        contig_filtered="results/filtered_contigs/length{LEN}up.all_contigs.fa".format(LEN=config["contig_filter_length"])
    log: 
        "logs/contigs/contig_filter.log"
    group: "contig_assembly"
    shell:
        """
        sed 's/len=/len= /g' {input} | \
        awk '{{if($0 ~ /^>/ && $5 >= {params.LEN}) {{print "\\n"$0; getline; print;}}}}' | \
        sed '/^$/d'| \
        sed '/^>/ s/ .*//' > {output.contig_filtered}
        &> {log}
        """


rule contig_filter_sort:
    input:
        rules.contig_filter.output.contig_filtered
    output:
        contig_filtered_sorted="results/filtered_contigs/length{LEN}up.all_contigs.sorted.fa".format(LEN=config["contig_filter_length"])
    log:
        "logs/contigs/contig_filter_sort.log"
    group: "contig_assembly"
    shell:
        """
        awk '/^>/ {{if (seq) print seq; seq=""; print $0; next}} {{seq=seq$0}} END {{if (seq) print seq}}' {input} | \
        paste - - | \
        sort -t$'\t' -k1,1 | \
        tr "\t" "\n" > {output.contig_filtered_sorted}
        """


rule build_minimap2_contig_index:
    input:
        contig=rules.contig_filter_sort.output.contig_filtered_sorted,
    params:
        LEN=config["contig_filter_length"]
    output:
        contig_index="results/minimap2/length{LEN}up.all_contigs.sorted.mmi".format(LEN=config["contig_filter_length"])
    log:
        "logs/minimap2/index_build_contig_length{params.LEN}.log",
    group:
        "minimap2"
    threads: 10
    conda:
        "envs/minimap2.yaml"
    shell:
        """
        minimap2 -d {output.contig_index} {input.contig} &> {log}       
        """



rule minimap2_contig_mapping:
    input:
        contig_index=rules.build_minimap2_contig_index.output,
        hm_removal_fa=rules.fq2fa.output.metagenome_fa
    output: 
        contig_bam="results/minimap2/contig_bam/{sample}.bam"
    log: 
        "logs/minimap2/alignment/contig_bam/{sample}.log"
    conda: 
        "envs/minimap2.yaml"  
    threads: 20
    group: "minimap2"
    shell:
        """
        minimap2 -t {threads} -N 5 -ax sr {input.contig_index} {input.hm_removal_fa} | \
        samtools view -F 3584 -b --threads {threads} > {output.contig_bam} 2> {log}
        """

rule prodigal:
    input:
        "results/filtered_contigs/length{LEN}up.all_contigs.fa".format(LEN=config["contig_filter_length"])
    output:
        cds_fa="results/prodigal/length{LEN}up/contig.genes.fna".format(LEN=config["contig_filter_length"]),
        protein_fa="results/prodigal/length{LEN}up/length{LEN}up.all_contigs.faa".format(LEN=config["contig_filter_length"]),
        prediction="results/prodigal/length{LEN}up/length{LEN}up.all_contigs.out".format(LEN=config["contig_filter_length"])
    log:"logs/prodigal/prodigal.log"
    conda:
        "envs/prodigal.yaml"
    threads:10
    shell:
        "prodigal -i {input} -d {output.cds_fa} -o {output.prediction} -a {output.protein_fa} 2> {log}"


rule contig_gene_filter:
    input:
        rules.prodigal.output.cds_fa
    params:
        G_LEN=config["contig_gene_length"],
        LEN=config["contig_filter_length"]
    output:
        gene_filtered="results/prodigal/length{LEN}up/length{G_LEN}up.contig.genes.fna".format(G_LEN=config["contig_gene_length"], LEN=config["contig_filter_length"])
    log:"logs/prodigal/contig_gene_filter.log"
    shell:
        """
        awk 'BEGIN {{RS=">"; FS="\\n"}} NR>1 {{header=$1; seq=""; for (i=2; i<=NF; i++) seq=seq $i; if (length(seq) > {params.G_LEN}) {{print ">" header "\\n" seq}}}}' {input}|sed '/^>/ s/ .*//' > {output} \
        2> {log}
        """

#change log name
rule build_minimap2_gene_index:
    input:
        gene=rules.contig_gene_filter.output
    params:
        G_LEN=config["contig_gene_length"],
        LEN=config["contig_filter_length"]
    output:
        gene_index="results/minimap2/length{G_LEN}up.contig.genes.mmi".format(G_LEN=config["contig_gene_length"])
    log:
        "logs/minimap2/index_build_gene_length{G_LEN}.log".format(G_LEN=config["contig_gene_length"])
    group:
        "minimap2"
    threads: 10
    conda:
        "envs/minimap2.yaml"
    shell:
        """
        minimap2 -d {output.gene_index} {input.gene} &> {log}
        """

# examine the gene expression level in each sample
rule minimap2_gene_mapping:
    input:
        gene_index=rules.build_minimap2_gene_index.output,
        hm_removal_fa=rules.fq2fa.output.metagenome_fa
    output:
        gene_bam="results/minimap2/gene_bam/{sample}.bam"
    log: "logs/minimap2/alignment/gene_bam/{sample}.log"
    conda:"envs/minimap2.yaml"  
    threads:20
    group:"minimap2"
    shell:
        """
        minimap2 -t {threads} -N 5 -ax sr {input.gene_index} {input.hm_removal_fa} | samtools view -F 3584 -b --threads {threads} > {output.gene_bam} 2> {log}
        """        


#rule bam_quality_check:
#    input:
        #gene_bam=expand("results/minimap2/gene_bam/{sample}.bam", sample=config["sample_reads"]),
        #contig_bam=expand("results/minimap2/contig_bam/{sample}.bam", sample=config["sample_reads"])
	#gene_bam_dir="results/minimap2/gene_bam",
	#contig_bam_dir="results/minimap2/contig_bam"
#    output:
        #corrupted_bam_genes=directory("results/minimap2/corrupted_bam_genes/"),
        #corrupted_bam_contigs=directory("results/minimap2/corrupted_bam_contigs/")
#    threads: 2
#    log:
#        gene_log="logs/minimap2/samtools/gene_bam_quality_check.log",
#        contig_log="logs/minimap2/samtools/contig_bam_quality_check.log"
#    conda:
#        "envs/minimap2.yaml" 
#    shell:
#        """
        #mkdir -p {output.corrupted_bam_genes}
        #mkdir -p {output.corrupted_bam_contigs}

        #for f in {input.gene_bam}; do
        #    samtools quickcheck -v $f || mv $f {output.corrupted_bam_genes}
        #    echo "Corrupted gene BAM moved: $f" >> {log.gene_log}

        #done
        #for f in {input.contig_bam}; do
        #    samtools quickcheck -v $f || mv $f {output.corrupted_bam_contigs}
        #    "Corrupted contig BAM moved: $f" >> {log.contig_log}
        #done 
 #       """

        

rule vamb_rpkm_contig:
    input:
        bam=expand("results/minimap2/contig_bam/{sample}.bam", sample=config['sample_reads']),
        fasta=rules.contig_filter_sort.output.contig_filtered_sorted
    params:
        minimum_contig_length=config["vamb_minimum_contig_length"],
    output:
        directory("results/vamb/contigs")
    log: "logs/vamb/vamb_rpkm_contig.log"
    conda:
        "envs/vamb.yaml"
    threads:10
    group:"vamb"
    shell:
        "vamb --outdir {output}  --fasta {input.fasta} --bamfiles {input.bam} -o C --minfasta {params.minimum_contig_length} 2> {log}"
        


rule vamb_rpkm_gene:
    input:
        bam=expand("results/minimap2/gene_bam/{sample}.bam", sample=config['sample_reads']),
        fasta=rules.contig_gene_filter.output.gene_filtered
    params:
        minimum_gene_length=config["vamb_minimum_gene_length"]
    output:
        directory("results/vamb/genes")
    log: "logs/vamb/vamb_rpkm_gene.log"
    conda:
        "envs/vamb.yaml"
    threads:10
    group:"vamb"
    shell:
        "vamb --outdir {output}  --fasta {input.fasta} --bamfiles {input.bam} -o C --minfasta {params.minimum_gene_length} 2> {log}"


rule RPKM_conversion:
    input:
        contigs_rpkm_raw = "results/vamb/contigs/rpkm.npz",
        gene_rpkm_raw = "results/vamb/genes/rpkm.npz"  
    output:
        rpkm_contigs = "results/rpkm/contigs_rpkm.csv",
        rpkm_genes = "results/rpkm/genes_rpkm.csv",
        contigs_lengths = "results/rpkm/contigs/contigs_lengths.csv",
        genes_lengths = "results/rpkm/genes/gene_lengths.csv"
    log: "logs/vamb/rpkm_conversion.log"
    run:
        import pandas as pd
        import numpy as np  

        # Load the RPKM data
        contig_rpkm_data = np.load(input.contigs_rpkm_raw)
        gene_rpkm_data = np.load(input.gene_rpkm_raw)

        with open(output.rpkm_contigs, 'w') as f:
            for key, value in contig_rpkm_data.items():
                np.savetxt(f, value, delimiter=",")
        
        with open(output.rpkm_genes, 'w') as f:
            for key, value in gene_rpkm_data.items():
                np.savetxt(f, value, delimiter=",")

        contig_length_data = np.load('results/vamb/contigs/lengths.npz')
        gene_length_data = np.load('results/vamb/genes/lengths.npz')
        
        with open(output.contigs_lengths, 'w') as f:
            for key, value in contig_length_data.items():
                np.savetxt(f, value, delimiter=",")
        
        with open(output.genes_lengths, 'w') as f:
            for key, value in gene_length_data.items():
                np.savetxt(f, value, delimiter=",")



rule bam2totalreads:
### -F 260 get all the aligned reads that does not have a secondary mapping
    input:
        contigs_bam="results/minimap2/contig_bam/{sample}.bam"
    output:
        contigs_bam_totalreads="results/rpkm/reads/total_reads/{sample}.total_reads"
    log:  "logs/vamb/bam2totalreads_{sample}.log"
    conda:"envs/minimap2.yaml"
    threads:20
    shell:
        "samtools view -c -F 260 {input.contigs_bam} > {output.contigs_bam_totalreads} 2> {log}"
    

rule bam2reads:
#unique reads 
    input:
        contigs_bam="results/minimap2/contig_bam/{sample}.bam"
    output:
        contigs_bam_reads="results/rpkm/reads/reads/{sample}.reads"
    log: "logs/vamb/bam2toreads_{sample}.log"
    conda:"envs/minimap2.yaml"
    threads:20
    shell:
        "samtools view -F 260 {input.contigs_bam} | awk '!seen[$1]++' | cut -f 3 | sort | uniq -c > {output.contigs_bam_reads} 2> {log}"
        

rule sample_total_reads:
    input:
        total_reads=expand("results/rpkm/reads/total_reads/{sample}.total_reads", sample=config['sample_reads'])
    output:
        total_reads_csv="results/rpkm/reads/sample_total_reads.csv"
    log: "logs/read/sample_total_reads.log"
    shell:
        """
        for i in {input.total_reads}; do
            echo -n "$(basename "$i" .total_reads), "; 
            cat "$i"; 
        done > {output.total_reads_csv} 2>{log}
        """

rule contig_reads_table:
    input:
        sample_total_reads="results/rpkm/reads/sample_total_reads.csv",
        rpkm="results/rpkm/contigs/formated_contigs_rpkm.csv",
        contig_lenth="results/rpkm/contigs/formated_contigs_length.csv"
    output:
        contig_reads_table="results/rpkm/contigs/contig_reads_table.csv"
    log:"logs/vamb/contigs_reads_table.log"
    threads:20
    shell:
        r"""
        Rscript workflow/scripts/RPKM2reads.R --rpkm {input.rpkm} --contig_length {input.contig_lenth} --sample_total_reads {input.sample_total_reads} --output {output.contig_reads_table} 2> {log}
        """


rule reformat_rpkm_table:
    input:
        # add the headers to the rpkm table 
        





rule checkM_setup:
    params:
        url=config["checkM_url"]
    output:
        directory("results/checkM/checkm_data_db")
    conda:"envs/checkkm.yaml"
    log:"logs/checkM/db_setup.log"
    threads:20
    shell:
        """
        wget --no-check-certificate {params.url} -O checkm_data.tar.gz > {log} 2>&1
   	    mkdir -p {output}
   	    tar -xvzf checkm_data.tar.gz -C {output} >> {log} 2>&1
   	    rm checkm_data.tar.gz >> {log} 2>&1
	    checkm data setRoot {output}
	    """


rule checkM_SGB:
    input:
        bins="results/vamb/contigs/bins"
    output:
        checkM_dir=directory("results/checkM/SGB")
    log:"logs/checkM/checkM_contigs.log"
    conda:"envs/checkkm.yaml"
    threads:60
    group:"checkM"
    shell:
        "checkm lineage_wf -t {threads} {input.bins} {output.checkM_dir} > {log} 2>&1"



#### Find potential viruses within the assembly
#rule vibrant_db:
#    output:"results/viral/vibrant_db_done.txt"
#    log:"logs/viral/vibrant/vibrant_db.log"
#    group:"viral"
#    shell:
#        """
#        if [ ! -d "VIBRANT" ]; then
#            git clone https://github.com/AnantharamanLab/VIBRANT >> {log} 2>&1
#            chmod -R 777 VIBRANT
#        fi
#	cd VIBRANT/databases
#	./VIBRANT_setup.py >> {log} 2>&1
#        echo "vibrant db initiated" > {output}
#	"""

rule vibrant:
    input:rules.contig_filter.output.contig_filtered
    output:directory("results/viral/vibrant")
    log: "logs/viral/vibrant/vibrant.log"
    conda: "envs/vibrant.yaml"
    threads:50
    group:"viral"
    shell:
        """
        VIBRANT/VIBRANT_run.py -i {input} -t {threads} -folder {output} 2> {log}
        """ 



#rule virosorter_db:
#    params:
#        url=config["vsorter_url"]
#    output:
#        directory("results/viral/vsorter/db")
#    log:"logs/viral/virosorter/vsorter_db.log"
#    conda:"envs/virosorter.yaml"
#    threads:50
#    group:"viral"
#    shell:
#        """
#        wget --no-check-certificate -O db.tgz {params.url} > {log} 2>&1
#        mkdir -p {output}
#        tar --strip-components=1 -xzf db.tgz -C {output} >> {log} 2>&1 
#	"""

#rule virosorter:
#    input:rules.contig_filter.output.contig_filtered
#    output:directory("results/viral/vsorter/vsorter2")
#    log:"logs/viral/virosorter/vsorter2.log"
#    conda:"vs2"
#    group:"viral"
#    threads:50
#    shell:
#        """
#        virsorter run -w {output} -i {input} -j {threads} >> {log} 2>&1
#        """


